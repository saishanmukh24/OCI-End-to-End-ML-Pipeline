# ğŸš€ End-to-End ML Pipeline on Oracle Cloud Infrastructure

[![Oracle Cloud](https://img.shields.io/badge/Oracle-Cloud-red?logo=oracle)](https://cloud.oracle.com/)
[![Python](https://img.shields.io/badge/Python-3.8+-blue?logo=python)](https://www.python.org/)
[![Docker](https://img.shields.io/badge/Docker-Enabled-blue?logo=docker)](https://www.docker.com/)
[![Model Accuracy](https://img.shields.io/badge/Model%20Accuracy-88%25-success)]()

## ğŸ“‹ Table of Contents
- [Project Overview](#project-overview)
- [Key Features](#key-features)
- [Architecture](#architecture)
- [Technologies Used](#technologies-used)
- [Folder Structure](#folder-structure)
- [Prerequisites](#prerequisites)
- [Setup Instructions](#setup-instructions)
- [Usage](#usage)
- [Model Performance](#model-performance)
- [CI/CD Pipeline](#cicd-pipeline)
- [Contributing](#contributing)
- [License](#license)

## ğŸ“– Project Overview

This project demonstrates a complete end-to-end machine learning pipeline built on **Oracle Cloud Infrastructure (OCI)**. The pipeline achieves **88% model accuracy** for predictive analytics tasks, leveraging cloud-native services, distributed computing, and automated MLOps practices.

The solution encompasses data ingestion, preprocessing, feature engineering, model training, hyperparameter optimization, deployment, and continuous monitoringâ€”all orchestrated on OCI's robust infrastructure.

## âœ¨ Key Features

- ğŸ”„ **Data Processing**: Comprehensive data preprocessing pipeline with feature selection and engineering for optimal model performance
- ğŸ¤– **Model Training**: Random Forest and XGBoost algorithms implemented on distributed systems for scalable training
- âš¡ **AutoML Optimization**: Automated hyperparameter tuning reducing training time by 50% while maintaining high accuracy
- ğŸ” **CI/CD Pipeline**: Fully automated pipeline for model retraining, deployment, and versioning
- ğŸ“Š **Monitoring Dashboards**: Real-time monitoring and alerting for model performance metrics
- ğŸ³ **Containerization**: Docker-based deployment for portability and scalability
- â˜ï¸ **Cloud-Native**: Leverages OCI Data Science services for enterprise-grade ML operations

## ğŸ—ï¸ Architecture

The pipeline follows a modular architecture:

```
Data Ingestion â†’ Preprocessing â†’ Feature Engineering â†’ Model Training â†’ Hyperparameter Tuning â†’ Model Evaluation â†’ Deployment â†’ Monitoring
```

**Key Components:**
- **OCI Data Science**: Model development and training environment
- **OCI Object Storage**: Data lake for raw and processed data
- **OCI Container Registry**: Docker image storage
- **OCI Functions**: Serverless inference endpoints
- **OCI Monitoring**: Performance tracking and alerting

## ğŸ› ï¸ Technologies Used

### Core Technologies
- **Python 3.8+**: Primary programming language
- **Oracle Cloud Infrastructure (OCI)**: Cloud platform and infrastructure
- **OCI Data Science**: Managed ML platform
- **Scikit-learn**: Machine learning library
- **XGBoost**: Gradient boosting framework
- **Docker**: Containerization platform

### ML Frameworks & Libraries
- **Random Forest**: Ensemble learning algorithm
- **XGBoost**: Extreme gradient boosting
- **Pandas**: Data manipulation
- **NumPy**: Numerical computing
- **Matplotlib/Seaborn**: Data visualization

### DevOps & MLOps
- **Git/GitHub**: Version control
- **Docker**: Container orchestration
- **OCI DevOps**: CI/CD automation
- **Jupyter Notebooks**: Interactive development

## ğŸ“ Folder Structure

```
OCI-End-to-End-ML-Pipeline/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Raw dataset files
â”‚   â”œâ”€â”€ processed/              # Cleaned and processed data
â”‚   â””â”€â”€ features/               # Engineered features
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb
â”‚   â”œâ”€â”€ 03_model_training.ipynb
â”‚   â””â”€â”€ 04_model_evaluation.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”‚   â””â”€â”€ feature_engineering.py
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”‚   â””â”€â”€ predict.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ logger.py
â”‚   â”‚   â””â”€â”€ helpers.py
â”‚   â”‚
â”‚   â””â”€â”€ deployment/
â”‚       â”œâ”€â”€ inference.py
â”‚       â””â”€â”€ monitor.py
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ trained_models/         # Saved model artifacts
â”‚   â””â”€â”€ checkpoints/            # Training checkpoints
â”‚
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ model_config.yaml
â”‚   â””â”€â”€ oci_config.yaml
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_preprocessing.py
â”‚   â”œâ”€â”€ test_models.py
â”‚   â””â”€â”€ test_inference.py
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_model.sh
â”‚   â”œâ”€â”€ deploy_model.sh
â”‚   â””â”€â”€ run_pipeline.sh
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â””â”€â”€ README.md
```

## ğŸ“‹ Prerequisites

- **Oracle Cloud Account** with access to:
  - OCI Data Science
  - OCI Object Storage
  - OCI Container Registry (optional)
- **Python 3.8+**
- **Docker** (for containerized deployment)
- **Git**
- **OCI CLI** (optional but recommended)

## ğŸš€ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/saishanmukh24/OCI-End-to-End-ML-Pipeline.git
cd OCI-End-to-End-ML-Pipeline
```

### 2. Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Configure OCI Credentials

Set up your OCI configuration file (`~/.oci/config`):

```ini
[DEFAULT]
user=ocid1.user.oc1...
fingerprint=your_fingerprint
tenancy=ocid1.tenancy.oc1...
region=us-ashburn-1
key_file=~/.oci/oci_api_key.pem
```

### 5. Update Configuration Files

Edit `config/oci_config.yaml` and `config/model_config.yaml` with your specific settings:

```yaml
# Example: config/oci_config.yaml
compartment_id: "ocid1.compartment.oc1..."
project_id: "ocid1.datascienceproject.oc1..."
bucket_name: "ml-pipeline-data"
```

### 6. Prepare Data

Place your dataset in the `data/raw/` directory or configure the data loader to fetch from OCI Object Storage.

## ğŸ’» Usage

### Training the Model

```bash
# Run the complete pipeline
python src/models/train.py --config config/model_config.yaml

# Or use the shell script
bash scripts/train_model.sh
```

### Making Predictions

```python
from src.models.predict import ModelPredictor

# Load the trained model
predictor = ModelPredictor(model_path="models/trained_models/best_model.pkl")

# Make predictions
predictions = predictor.predict(new_data)
```

### Running in Docker

```bash
# Build the Docker image
docker build -t oci-ml-pipeline:latest -f docker/Dockerfile .

# Run the container
docker run -v $(pwd)/data:/app/data oci-ml-pipeline:latest
```

### Jupyter Notebooks

```bash
jupyter notebook notebooks/
```

Explore the notebooks in sequential order for a guided walkthrough of the pipeline.

## ğŸ“Š Model Performance

| Metric | Value |
|--------|-------|
| **Accuracy** | 88% |
| **Precision** | 0.86 |
| **Recall** | 0.84 |
| **F1-Score** | 0.85 |
| **Training Time Reduction** | 50% (with AutoML) |

### Algorithm Comparison

| Algorithm | Accuracy | Training Time |
|-----------|----------|---------------|
| Random Forest | 85% | 45 min |
| XGBoost | 88% | 30 min |
| Logistic Regression | 78% | 10 min |

## ğŸ” CI/CD Pipeline

The project includes automated CI/CD workflows:

1. **Continuous Integration**:
   - Automated testing on every commit
   - Code quality checks
   - Model validation

2. **Continuous Deployment**:
   - Automated model retraining on new data
   - Model versioning and registry
   - Blue-green deployment strategy
   - Performance monitoring and rollback

3. **Monitoring**:
   - Real-time model performance tracking
   - Data drift detection
   - Automated alerting

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is open source and available under the [MIT License](LICENSE).

## ğŸ‘¤ Author

**Sai Shanmukh**
- GitHub: [@saishanmukh24](https://github.com/saishanmukh24)

## ğŸ“ Contact

For questions or collaboration opportunities, please open an issue or reach out through GitHub.

---

**Project Date**: October 2025

â­ If you find this project helpful, please consider giving it a star!
